count(word, Product) %>%
group_by(Product) %>%
top_n(10, n) %>%
ungroup() %>%
mutate(word2 = fct_reorder(word, n))
ggplot(word_counts_2, aes(x = word2, y = n, group = Product)) +
geom_col() +
facet_wrap(~ Product, scales = "free_y") +
coord_flip() +
ggtitle("Review Word Counts")
word_counts_2 = tidy_review_2 %>%
count(word, Product) %>%
group_by(Product) %>%
top_n(10, n) %>%
ungroup() %>%
mutate(word2 = fct_reorder(word, n))
ggplot(word_counts_2, aes(x = word2, y = n, fill = Product)) +
geom_col() +
facet_wrap(~ Product, scales = "free_y") +
coord_flip() +
ggtitle("Review Word Counts")
word_counts_2 = tidy_review_2 %>%
count(word, Product) %>%
group_by(Product) %>%
top_n(10, n) %>%
ungroup() %>%
mutate(word2 = fct_reorder(word, n))
ggplot(word_counts_2, aes(x = word2, y = n, fill = Product)) +
geom_col(show.legend = FALSE) +
facet_wrap(~ Product, scales = "free_y") +
coord_flip() +
ggtitle("Review Word Counts")
install.packages("wordcloud")
library(wordcloud)
word_counts_3 = tidy_review_2 %>%
count(word)
wordcloud(
words = word_counts_3$word,
freq = word_counts_3$n,
max.words = 30
)
wordcloud(
words = word_counts_3$word,
freq = word_counts_3$n,
max.words = 30,
colors = "blue"
)
knitr::opts_chunk$set(echo = TRUE)
get_sentiments("bing")
get_sentiments("bing") %>%
count(sentiment)
get_sentiments("afinn")
install.packages("textdata")
get_sentiments("afinn")
get_sentiments("afinn") %>%
summarise(
min = min(value),
max = max(value)
)
get_sentiments("loughran")
get_sentiments("loughran") %>%
count(sentiment)
get_sentiments("loughran") %>%
count(sentiment) %>%
mutate(sentiment2 = fct_reorder(sentiment, n)) %>%
ggplot(aes(x = sentiment2, y = n)) + geom_col() + coord_flip() + ggtitle("Visualisation of Loughran dictionary")
get_sentiments("loughran") %>%
count(sentiment) %>%
mutate(sentiment2 = fct_reorder(sentiment, n)) %>%
ggplot(aes(x = sentiment2, y = n)) + geom_col() + coord_flip() + labs(x = "Sentiment", y = "Counts", title = "Visualisation of Loughran dictionary")
get_sentiments("nrc")
get_sentiments("nrc") %>%
count(sentiment) %>%
arrange(desc(n))
get_sentiments("nrc") %>%
count(sentiment) %>%
mutate(sentiment2 = fct_reorder(sentiment, n)) %>%
ggplot(aes(x = sentiment2, y = n)) + geom_col() + coord_flip() + labs(x = "Sentiment", y = "Counts", title = "Sentiment Counts in NRC")
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(tidytext)
get_sentiments("bing")
get_sentiments("bing") %>%
count(sentiment)
get_sentiments("afinn")
get_sentiments("afinn") %>%
summarise(
min = min(value),
max = max(value)
)
get_sentiments("loughran")
get_sentiments("loughran") %>%
count(sentiment)
get_sentiments("loughran") %>%
count(sentiment) %>%
mutate(sentiment2 = fct_reorder(sentiment, n)) %>%
ggplot(aes(x = sentiment2, y = n)) + geom_col() + coord_flip() + labs(x = "Sentiment", y = "Counts", title = "Visualisation of Loughran dictionary")
get_sentiments("nrc")
get_sentiments("nrc") %>%
count(sentiment) %>%
arrange(desc(n))
get_sentiments("nrc") %>%
count(sentiment) %>%
mutate(sentiment2 = fct_reorder(sentiment, n)) %>%
ggplot(aes(x = sentiment2, y = n)) + geom_col() + coord_flip() + labs(x = "Sentiment", y = "Counts", title = "Sentiment Counts in NRC")
reviews = read_csv("Datasets/Roomba Reviews.csv")
reviews
View(reviews)
review_tokens = reviews %>%
unnest_tokens(word, Review)
View(review_tokens)
review_tokens = reviews %>%
mutate(id = row_number()) %>%
unnest_tokens(word, Review)
stop_words
my_stop_words = tribble(
~word, ~lexicon,
"roomba", "CUSTOM",
"2", "CUSTOM"
)
All_stopwords = stop_words %>%
rbind(my_stop_words)
rm(my_stop_words)
View(All_stopwords)
no_stopword_tokens = review_tokens %>%
anti_join(All_stopwords)
no_stopword_tokens %>%
inner_join(get_sentiments("loughran"))
sentiment_reviews = no_stopword_tokens %>%
inner_join(get_sentiments("loughran"))
View(sentiment_reviews)
sentiment_reviews %>%
count(sentiment)
sentiment_reviews %>%
count(sentiment, word) %>%
arrange(desc(n))
sentiment_reviews %>%
filter(sentiment %in% c("positive", "negative")) %>%
count(sentiment, word) %>%
group_by(sentiment) %>%
top_n(10, n) %>%
mutate(word2 = fct_reorder(word)) %>%
ggplot(aes(x = word2, y = n)) + geom_col() + coord_flip() + labs(title = "Review Counts")
sentiment_reviews %>%
sentiment_reviews %>%
filter(sentiment %in% c("positive", "negative")) %>%
count(sentiment, word) %>%
group_by(sentiment) %>%
top_n(10, n) %>%
ungroup() %>%
mutate(word2 = fct_reorder(word)) %>%
ggplot(aes(x = word2, y = n)) + geom_col() + coord_flip() + labs(title = "Review Counts")
View(sentiment_reviews)
sentiment_reviews %>%
filter(sentiment %in% c("positive", "negative")) %>%
count(sentiment, word) %>%
group_by(sentiment) %>%
top_n(10, n) %>%
ungroup() %>%
mutate(word2 = fct_reorder(word, n)) %>%
ggplot(aes(x = word2, y = n)) + geom_col() + coord_flip() + labs(title = "Review Counts")
sentiment_reviews %>%
filter(sentiment %in% c("positive", "negative")) %>%
count(sentiment, word) %>%
group_by(sentiment) %>%
top_n(10, n) %>%
ungroup() %>%
mutate(word2 = fct_reorder(word, n)) %>%
ggplot(aes(x = word2, y = n, fill = sentiment)) + geom_col() + coord_flip() + facet_wrap(~ sentiment, scales = "free_y") + labs(title = "Review Counts")
sentiment_reviews %>%
filter(sentiment %in% c("positive", "negative")) %>%
count(sentiment, word) %>%
group_by(sentiment) %>%
top_n(10, n) %>%
ungroup() %>%
mutate(word2 = fct_reorder(word, n)) %>%
ggplot(aes(x = word2, y = n, fill = sentiment)) + geom_col(show.legend = FALSE) + coord_flip() + facet_wrap(~ sentiment, scales = "free_y") + labs(title = "Review Counts")
sentiment_reviews %>%
filter(sentiment %in% c("positive", "negative")) %>%
count(sentiment, word) %>%
group_by(sentiment) %>%
top_n(10, n) %>%
ungroup() %>%
mutate(word2 = fct_reorder(word, n)) %>%
ggplot(aes(x = word2, y = n, fill = sentiment)) + geom_col(show.legend = FALSE) + coord_flip() + facet_wrap(~ sentiment, scales = "free") + labs(title = "Review Counts")
no_stopword_tokens %>%
inner_join("bing") %>%
count(stars, sentiment)
no_stopword_tokens %>%
inner_join(get_sentiments("bing")) %>%
count(stars, sentiment)
View(no_stopword_tokens)
no_stopword_tokens %>%
inner_join(get_sentiments("bing"))
no_stopword_tokens %>%
inner_join(get_sentiments("bing")) %>%
count(Stars, sentiment)
wider_counts = no_stopword_tokens %>%
inner_join(get_sentiments("bing")) %>%
count(Stars, sentiment) %>%
spread(sentiment, value = n)
View(wider_counts)
wider_counts %>%
mutate(overall_sentiment = positive - negative)
wider_counts = wider_counts %>%
mutate(overall_sentiment = positive - negative)
wider_counts %>%
mutate(Stars2 = fct_reorder(Stars, overall_sentiment)) %>%
ggplot(aes(x = Stars2, y = overall_sentiment, fill = as.factor(Stars2))) +
geom_col(show.legend = FALSE) +
coord_flip() +
labs(title = "Overall Sentiment by Stars",
subtitle = "Reviews for Robotic Vacuum",
x = "Stars",
y = "Overall Sentiment")
wider_counts %>%
mutate(Stars2 = fct_reorder(Stars, overall_sentiment)) %>%
ggplot(aes(x = Stars2, y = overall_sentiment, fill = Stars2)) +
geom_col(show.legend = FALSE) +
coord_flip() +
labs(title = "Overall Sentiment by Stars",
subtitle = "Reviews for Robotic Vacuum",
x = "Stars",
y = "Overall Sentiment")
wider_counts = wider_counts %>%
mutate(overall_sentiment = positive - negative)
wider_counts %>%
mutate(Stars2 = fct_reorder(Stars, overall_sentiment))
wider_counts = wider_counts %>%
mutate(overall_sentiment = positive - negative)
wider_counts = wider_counts %>%
mutate(overall_sentiment = positive - negative) %>%
mutate(Stars2 = fct_reorder(Stars, overall_sentiment))
wider_counts = wider_counts %>%
mutate(overall_sentiment = positive - negative) %>%
mutate(Stars = fct_reorder(Stars, overall_sentiment))
class(wider_counts$Stars)
wider_counts = wider_counts %>%
mutate(overall_sentiment = positive - negative) %>%
mutate(Stars2 = fct_reorder(Stars, overall_sentiment))
wider_counts = wider_counts %>%
mutate(overall_sentiment = positive - negative) %>%
mutate(Stars2 = fct_reorder(char(Stars), overall_sentiment))
wider_counts = wider_counts %>%
mutate(overall_sentiment = positive - negative) %>%
mutate(Stars2 = fct_reorder(as.character(Stars), overall_sentiment))
wider_counts = wider_counts %>%
mutate(overall_sentiment = positive - negative)
wider_counts = no_stopword_tokens %>%
inner_join(get_sentiments("bing")) %>%
count(Stars, sentiment) %>%
spread(sentiment, value = n)
wider_counts = wider_counts %>%
mutate(overall_sentiment = positive - negative)
wider_counts %>%
mutate(Stars2 = fct_reorder(as.character(Stars), overall_sentiment)) %>%
ggplot(aes(x = Stars2, y = overall_sentiment, fill = as.factor(Stars2))) +
geom_col(show.legend = FALSE) +
coord_flip() +
labs(title = "Overall Sentiment by Stars",
subtitle = "Reviews for Robotic Vacuum",
x = "Stars",
y = "Overall Sentiment")
wider_counts %>%
mutate(Stars2 = fct_reorder(as.character(Stars), overall_sentiment)) %>%
ggplot(aes(x = Stars2, y = overall_sentiment, fill = Stars2)) +
geom_col(show.legend = FALSE) +
coord_flip() +
labs(title = "Overall Sentiment by Stars",
subtitle = "Reviews for Robotic Vacuum",
x = "Stars",
y = "Overall Sentiment")
class(wider_counts$Stars)
wider_counts = wider_counts %>%
mutate(overall_sentiment = positive - negative) %>%
mutate(Stars2 = fct_reorder(as.character(Stars), overall_sentiment))
class(wider_counts$Stars2)
wider_counts = no_stopword_tokens %>%
inner_join(get_sentiments("bing")) %>%
count(Stars, sentiment) %>%
spread(sentiment, value = n)
wider_counts = wider_counts %>%
mutate(Stars2 = fct_reorder(Stars, overall_sentiment))
wider_counts = wider_counts %>%
mutate(overall_sentiment = positive - negative)
wider_counts = wider_counts %>%
mutate(Stars2 = fct_reorder(Stars, overall_sentiment))
wider_counts = wider_counts %>%
mutate(Stars2 = fct_reorder(as.character(Stars), overall_sentiment))
wider_counts %>%
ggplot(aes(x = Stars2, y = overall_sentiment, fill = Stars2)) +
geom_col(show.legend = FALSE) +
coord_flip() +
labs(title = "Overall Sentiment by Stars",
subtitle = "Reviews for Robotic Vacuum",
x = "Stars",
y = "Overall Sentiment")
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(tidytext)
reviews = read_csv("Datasets/Roomba Reviews.csv")
reviews = reviews %>%
mutate(id = row_number())
tokenised_reviews = reviews %>%
unnest_tokens(word, Review)
# define a customised stop words tibble
my_stopwords = tribble(
~word, ~lexicon,
"roomba", "CUSTOM",
"2", "CUSTOM"
)
# combine my_stopwords and stop_words
All_stopwords = stop_words %>%
rbind(my_stopwords)
# remove stop words from tokens
no_stopword_tokenised_reviews = tokenised_reviews %>%
anti_join(All_stopwords)
# define a customised stop words tibble
my_stopwords = tribble(
~word, ~lexicon,
"roomba", "CUSTOM",
"2", "CUSTOM"
)
# combine my_stopwords and stop_words
All_stopwords = stop_words %>%
rbind(my_stopwords)
# remove stop words from tokens
no_stopword_tokenised_reviews = tokenised_reviews %>%
anti_join(All_stopwords)
rm(my_stopwords, All_stopwordss)
rm(my_stopwords, All_stopwords)
# define a customised stop words tibble
my_stopwords = tribble(
~word, ~lexicon,
"roomba", "CUSTOM",
"2", "CUSTOM"
)
# combine my_stopwords and stop_words
All_stopwords = stop_words %>%
rbind(my_stopwords)
# remove stop words from tokens
no_stopword_tokenised_reviews = tokenised_reviews %>%
anti_join(All_stopwords)
rm(my_stopwords, All_stopwords)
no_stopword_tokenised_reviews %>%
count(word, id) %>%
cast_dtm(id, word, n)
no_stopword_tokenised_reviews %>%
count(word, id) %>%
cast_dtm(id, word, n)
install.packages("tm")
no_stopword_tokenised_reviews %>%
count(word, id) %>%
cast_dtm(id, word, n)
dtm_reviews = no_stopword_tokenised_reviews %>%
count(word, id) %>%
cast_dtm(id, word, n) %>%
as.matrix()
dtm_reviews[1:4, 2000:2004]
install.packages("topicmodels")
library(topicmodels)
lda_out = LDA(
dtm_reviews,
k = 2,
method = "Gibbs",
control =list(seed=42)
)
lda_out
glimpse(lda_out)
lda_topics = lda_out %>%
tidy(matrix = "beta") %>%
arrange(desc(beta))
View(lda_topics)
lda_topics %>%
mutate(term2 = fct_reorder(term, beta)) %>%
ggplot(aes(x = term2, y = beta, fill = topic)) +
geom_col(show.legend = FALSE) +
facet_wrap(~topic, scales = "free") +
coord_flip()
lda_topics %>%
group_by(topic) %>%
top_n(10, beta) %>%
ungroup() %>%
mutate(term2 = fct_reorder(term, beta)) %>%
ggplot(aes(x = term2, y = beta, fill = topic)) +
geom_col(show.legend = FALSE) +
facet_wrap(~topic, scales = "free") +
coord_flip()
document_topics = lda_out %>%
tidy(matrix = "gamma")
document_topics
document_topics = lda_out %>%
tidy(matrix = "gamma")
document_topics
wider_document_topics = document_topics %>%
spread(topic, gamma)
wider_document_topics
lda_topics %>%
group_by(topic) %>%
top_n(15, beta) %>%
ungroup() %>%
mutate(term2 = fct_reorder(term, beta)) %>%
ggplot(aes(x = term2, y = beta, fill = topic)) +
geom_col(show.legend = FALSE) +
facet_wrap(~topic, scales = "free") +
coord_flip()
# visualisation
lda_topics2 %>%
group_by(topic) %>%
top_n(15, beta) %>%
ungroup() %>%
mutate(term2 = fct_reorder(term, beta)) %>%
ggplot(aes(x = term2, y = beta, fill = topic)) +
geom_col(show.legend = FALSE) +
facet_wrap(~topic, scales = "free") +
coord_flip()
# modeling
lda_out2 = LDA(
dtm_reviews,
k = 3,
method = "Gibbs",
control = list(seed(42))
)
# modeling
lda_out2 = LDA(
dtm_reviews,
k = 3,
method = "Gibbs",
control = list(seed=42)
)
# extract beta (probability)
lda_topics2 = tidy(lda_out2, matrix = "beta") %>%
arrange(beta)
# visualisation
lda_topics2 %>%
group_by(topic) %>%
top_n(15, beta) %>%
ungroup() %>%
mutate(term2 = fct_reorder(term, beta)) %>%
ggplot(aes(x = term2, y = beta, fill = topic)) +
geom_col(show.legend = FALSE) +
facet_wrap(~topic, scales = "free") +
coord_flip()
# modeling
lda_out3 = LDA(
dtm_reviews,
k = 4,
method = "Gibbs",
control = list(seed=42)
)
# extract beta (probability)
lda_topics3 = tidy(lda_out3, matrix = "beta") %>%
arrange(beta)
# visualisation
lda_topics3 %>%
group_by(topic) %>%
top_n(15, beta) %>%
ungroup() %>%
mutate(term2 = fct_reorder(term, beta)) %>%
ggplot(aes(x = term2, y = beta, fill = topic)) +
geom_col(show.legend = FALSE) +
facet_wrap(~topic, scales = "free") +
coord_flip()
lda_topics %>%
group_by(topic) %>%
top_n(15, beta) %>%
ungroup() %>%
mutate(term2 = fct_reorder(term, beta)) %>%
ggplot(aes(x = term2, y = beta, fill = as.factor(topic))) +
geom_col(show.legend = FALSE) +
facet_wrap(~topic, scales = "free") +
coord_flip()
# modeling
lda_out2 = LDA(
dtm_reviews,
k = 3,
method = "Gibbs",
control = list(seed=42)
)
# extract beta (probability)
lda_topics2 = tidy(lda_out2, matrix = "beta") %>%
arrange(beta)
# visualisation
lda_topics2 %>%
group_by(topic) %>%
top_n(15, beta) %>%
ungroup() %>%
mutate(term2 = fct_reorder(term, beta)) %>%
ggplot(aes(x = term2, y = beta, fill = as.factor(topic))) +
geom_col(show.legend = FALSE) +
facet_wrap(~topic, scales = "free") +
coord_flip()
# modeling
lda_out3 = LDA(
dtm_reviews,
k = 4,
method = "Gibbs",
control = list(seed=42)
)
# extract beta (probability)
lda_topics3 = tidy(lda_out3, matrix = "beta") %>%
arrange(beta)
# visualisation
lda_topics3 %>%
group_by(topic) %>%
top_n(15, beta) %>%
ungroup() %>%
mutate(term2 = fct_reorder(term, beta)) %>%
ggplot(aes(x = term2, y = beta, fill = as.factor(topic))) +
geom_col(show.legend = FALSE) +
facet_wrap(~topic, scales = "free") +
coord_flip()
